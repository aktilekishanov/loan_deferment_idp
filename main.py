import os
from datetime import datetime, date
import re
import json
import io
import time
import random
import tempfile
import base64
import pandas as pd

try:
    import fitz  # PyMuPDF
except Exception:
    fitz = None

import boto3
from botocore.exceptions import ClientError
import streamlit as st

# ======================= UI –ß–ê–°–¢–¨ =========================
st.set_page_config(page_title="S3 File Uploader", layout="centered")

st.write("")
st.title("–ü—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –æ—Ç—Å—Ä–æ—á–∫–∏ –ø–æ –ë–ó–ö")
st.write("–ü—Ä–∏—á–∏–Ω–∞: –í—ã—Ö–æ–¥ –≤ –æ—Ç–ø—É—Å–∫ –ø–æ —É—Ö–æ–¥—É –∑–∞ —Ä–µ–±–µ–Ω–∫–æ–º (–¥–µ–∫—Ä–µ—Ç)")

# --- –û—Å–Ω–æ–≤–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã ---
AWS_PROFILE = ""   # –ø—Ä–æ—Ñ–∏–ª—å AWS –∏–∑ ~/.aws/credentials (–æ—Å—Ç–∞–≤—å—Ç–µ –ø—É—Å—Ç—ã–º –¥–ª—è env/role)
AWS_REGION = "us-east-1"   # —Ä–µ–≥–∏–æ–Ω AWS
BEDROCK_REGION = "us-east-1"  # —Ä–µ–≥–∏–æ–Ω Bedrock
MODEL_ID = "anthropic.claude-3-7-sonnet-20250219-v1:0"  # –∏—Å–ø–æ–ª—å–∑—É–µ–º–∞—è LLM –º–æ–¥–µ–ª—å —Å vision
BUCKET_NAME = "loan-deferment-idp-test-tlek"  # –∏–º—è S3-–±–∞–∫–µ—Ç–∞
KEY_PREFIX = "uploads/"  # –±–∞–∑–æ–≤—ã–π –ø—Ä–µ—Ñ–∏–∫—Å –¥–ª—è –∑–∞–≥—Ä—É–∑–æ–∫

# Inference Profile for Claude 3.7 Sonnet (can be ID or ARN). ARN is recommended.
DEFAULT_INFERENCE_PROFILE_ID = "us.anthropic.claude-3-7-sonnet-20250219-v1:0"
DEFAULT_INFERENCE_PROFILE_ARN = "arn:aws:bedrock:us-east-1:183295407481:inference-profile/us.anthropic.claude-3-7-sonnet-20250219-v1:0"


# ======================= –ö–û–ù–°–¢–ê–ù–¢–´ –ò –£–¢–ò–õ–ò–¢–´ =========================
# –í–∞—Ä–∏–∞–Ω—Ç—ã —Ç–∏–ø–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞ (–æ—Ç–æ–±—Ä–∞–∂–∞–µ–º—ã–µ –º–µ—Ç–∫–∏)
DOC_TYPE_OPTIONS = [
    "–õ–∏—Å—Ç –≤—Ä–µ–º–µ–Ω–Ω–æ–π –Ω–µ—Ç—Ä—É–¥–æ—Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ (–±–æ–ª—å–Ω–∏—á–Ω—ã–π –ª–∏—Å—Ç)",
    "–ü—Ä–∏–∫–∞–∑ –æ –≤—ã—Ö–æ–¥–µ –≤ –¥–µ–∫—Ä–µ—Ç–Ω—ã–π –æ—Ç–ø—É—Å–∫ –ø–æ —É—Ö–æ–¥—É –∑–∞ —Ä–µ–±–µ–Ω–∫–æ–º",
    "–°–ø—Ä–∞–≤–∫–∞ –æ –≤—ã—Ö–æ–¥–µ –≤ –¥–µ–∫—Ä–µ—Ç–Ω—ã–π –æ—Ç–ø—É—Å–∫ –ø–æ —É—Ö–æ–¥—É –∑–∞ —Ä–µ–±–µ–Ω–∫–æ–º",
]

# –ú–∞–ø–ø–∏–Ω–≥ –∏–∑ –º–µ—Ç–æ–∫ UI –∫ –∫–æ—Ä–æ—Ç–∫–∏–º –∑–Ω–∞—á–µ–Ω–∏—è–º
DOC_TYPE_VALUE_MAP = {
    "–õ–∏—Å—Ç –≤—Ä–µ–º–µ–Ω–Ω–æ–π –Ω–µ—Ç—Ä—É–¥–æ—Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ (–±–æ–ª—å–Ω–∏—á–Ω—ã–π –ª–∏—Å—Ç)": "–õ–∏—Å—Ç",
    "–ü—Ä–∏–∫–∞–∑ –æ –≤—ã—Ö–æ–¥–µ –≤ –¥–µ–∫—Ä–µ—Ç–Ω—ã–π –æ—Ç–ø—É—Å–∫ –ø–æ —É—Ö–æ–¥—É –∑–∞ —Ä–µ–±–µ–Ω–∫–æ–º": "–ü—Ä–∏–∫–∞–∑",
    "–°–ø—Ä–∞–≤–∫–∞ –æ –≤—ã—Ö–æ–¥–µ –≤ –¥–µ–∫—Ä–µ—Ç–Ω—ã–π –æ—Ç–ø—É—Å–∫ –ø–æ —É—Ö–æ–¥—É –∑–∞ —Ä–µ–±–µ–Ω–∫–æ–º": "–°–ø—Ä–∞–≤–∫–∞",
}

# –°–æ–æ–±—â–µ–Ω–∏—è –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏–∏ –ú–ò–ë (—É—Å–ø–µ—à–Ω—ã–µ —Ç–µ–∫—Å—Ç—ã –¥–ª—è –∑–µ–ª—ë–Ω—ã—Ö —Å—Ç–∞—Ç—É—Å–æ–≤)
MIB_RULES = {
    "–§–ò–û –∑–∞—è–≤–∏—Ç–µ–ª—è –∏ –§–ò–û –≤ –¥–æ–∫—É–º–µ–Ω—Ç–µ –¥–æ–ª–∂–Ω—ã —Å–æ–≤–ø–∞–¥–∞—Ç—å": {
        "success": "–§–ò–û —Å–æ–≤–ø–∞–¥–∞–µ—Ç.",
    },
    "–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞": {
        "success": "–¢–∏–ø –¥–æ–∫—É–º–µ–Ω—Ç–∞ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥—ë–Ω.",
    },
    "–ê–∫—Ç—É–∞–ª—å–Ω–∞—è –¥–∞—Ç–∞": {
        "success": "–î–æ–∫—É–º–µ–Ω—Ç –≤ –ø—Ä–µ–¥–µ–ª–∞—Ö —Å—Ä–æ–∫–∞ –∞–∫—Ç—É–∞–ª—å–Ω–æ—Å—Ç–∏.",
    },
    "–ù–∞–ª–∏—á–∏–µ QR –∏–ª–∏ –ø–µ—á–∞—Ç–∏": {
        "success": "–û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –ø–µ—á–∞—Ç—å –∏/–∏–ª–∏ QR.",
    },
    "–ü—Ä–∏–∫—Ä–µ–ø–ª–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å –æ–¥–∏–Ω –¥–æ–∫—É–º–µ–Ω—Ç": {
        "success": "–ó–∞–≥—Ä—É–∂–µ–Ω –æ–¥–∏–Ω –¥–æ–∫—É–º–µ–Ω—Ç (1 —Å—Ç—Ä–∞–Ω–∏—Ü–∞ PDF).",
    },
}

# –°—Ä–æ–∫–∏ –∞–∫—Ç—É–∞–ª—å–Ω–æ—Å—Ç–∏ –ø–æ —Ç–∏–ø—É –¥–æ–∫—É–º–µ–Ω—Ç–∞ (–∫–∞–ª–µ–Ω–¥–∞—Ä–Ω—ã–µ –¥–Ω–∏)
VALIDITY_DAYS = {"–õ–∏—Å—Ç": 180, "–ü—Ä–∏–∫–∞–∑": 30, "–°–ø—Ä–∞–≤–∫–∞": 10}

def norm_name(val: str | None) -> str | None:
    """–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –§–ò–û: —Ç—Ä–∏–º–º–∏–Ω–≥, –Ω–∏–∂–Ω–∏–π —Ä–µ–≥–∏—Å—Ç—Ä, —É–¥–∞–ª–µ–Ω–∏–µ –ª–∏—à–Ω–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤."""
    if not isinstance(val, str) or not val.strip():
        return None
    s = re.sub(r"\s+", " ", val.strip()).lower()
    s = re.sub(r"[^a-z–∞-—è—ë\s-]", "", s)
    s = re.sub(r"\s+", " ", s)
    return s

def format_date_ddmmyyyy(val) -> str:
    """–ï–¥–∏–Ω–æ–µ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–∞—Ç—ã –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è: DD/MM/YYYY. –ü—Ä–∏–Ω–∏–º–∞–µ—Ç str | datetime | date | None."""
    d: date | None = None
    if isinstance(val, str):
        d = parse_date_safe(val)
    elif isinstance(val, datetime):
        d = val.date()
    elif isinstance(val, date):
        d = val
    if d is None:
        return "‚Äî"
    return d.strftime("%d/%m/%Y")

# –°–æ–æ–±—â–µ–Ω–∏—è –∏ –∫–æ–¥—ã –æ—à–∏–±–æ–∫ –ú–ò–ë (–¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è/–∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏)
MIB_ERRORS = {
    # –ö–ª—é—á–∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—Ç –∑–∞–≥–æ–ª–æ–≤–∫–∞–º –ø—Ä–æ–≤–µ—Ä–æ–∫/–ø–æ–ª–µ–π –≤ UI
    "–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞": {
        "message": "–ù–µ –≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –¥–æ–∫—É–º–µ–Ω—Ç–∞. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø—Ä–æ–≤–µ—Ä—å—Ç–µ –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö",
        "code": "01",
    },
    "–ê–∫—Ç—É–∞–ª—å–Ω–∞—è –¥–∞—Ç–∞": {
        "message": "–ù–µ –≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –¥–æ–∫—É–º–µ–Ω—Ç–∞. –ó–∞–≥—Ä—É–∑–∏—Ç–µ –ø–æ–∂–∞–ª—É–π—Å—Ç–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π –¥–æ–∫—É–º–µ–Ω—Ç —Å –∞–∫—Ç—É–∞–ª—å–Ω–æ–π –¥–∞—Ç–æ–π. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞ –ø—Ä–æ–≤–µ—Ä—å—Ç–µ –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö",
        "code": "03",
    },
    "–ü—Ä–∏–∫—Ä–µ–ø–ª–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å –æ–¥–∏–Ω –¥–æ–∫—É–º–µ–Ω—Ç": {
        "message": "–ù–µ –≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –¥–æ–∫—É–º–µ–Ω—Ç–∞. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞ –ø—Ä–∏–∫—Ä–µ–ø–∏—Ç–µ —Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω –¥–æ–∫—É–º–µ–Ω—Ç –≤ –æ–¥–Ω–æ–º —Ñ–∞–π–ª–µ",
        "code": "04",
    },
    "–§–ò–û –∑–∞—è–≤–∏—Ç–µ–ª—è –∏ –§–ò–û –≤ –¥–æ–∫—É–º–µ–Ω—Ç–µ –¥–æ–ª–∂–Ω—ã —Å–æ–≤–ø–∞–¥–∞—Ç—å": {
        "message": "–ù–µ –≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –¥–æ–∫—É–º–µ–Ω—Ç–∞. –ù–µ–∫–æ—Ç–æ—Ä—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –Ω–µ –æ—Ç–Ω–æ—Å—è—Ç—Å—è –∫ –∑–∞—è–≤–∏—Ç–µ–ª—é. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞ –ø—Ä–æ–≤–µ—Ä—å—Ç–µ –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö.",
        "code": "05",
    },
    "–ù–∞–ª–∏—á–∏–µ QR –∏–ª–∏ –ø–µ—á–∞—Ç–∏": {
        "message": "–ù–µ –≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –¥–æ–∫—É–º–µ–Ω—Ç–∞. –ù–µ–∫–æ—Ç–æ—Ä—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –Ω–µ —Å–æ–¥–µ—Ä–∂–∞—Ç –≤ —Å–µ–±–µ –ø–µ—á–∞—Ç—å/QR –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞ –ø—Ä–æ–≤–µ—Ä—å—Ç–µ –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö",
        "code": "06",
    },
}

def norm_doc_type(val: str | None) -> str | None:
    """–ü—Ä–∏–≤–µ–¥–µ–Ω–∏–µ —Ç–∏–ø–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –∫ –æ–¥–Ω–æ–º—É –∏–∑ –∑–Ω–∞—á–µ–Ω–∏–π: –õ–∏—Å—Ç | –ü—Ä–∏–∫–∞–∑ | –°–ø—Ä–∞–≤–∫–∞."""
    if not isinstance(val, str) or not val.strip():
        return None
    s = val.strip().lower()
    if "–ª–∏—Å—Ç" in s:
        return "–õ–∏—Å—Ç"
    if "–ø—Ä–∏–∫–∞–∑" in s:
        return "–ü—Ä–∏–∫–∞–∑"
    if "—Å–ø—Ä–∞–≤–∫" in s:
        return "–°–ø—Ä–∞–≤–∫–∞"
    if s in ("–ª–∏—Å—Ç", "–ø—Ä–∏–∫–∞–∑", "—Å–ø—Ä–∞–≤–∫–∞"):
        return s.capitalize()
    return None


def parse_date_safe(s: str | None):
    """–ü—Ä–æ–±—É–µ–º —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å –¥–∞—Ç—É –≤ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –ø–æ–ø—É–ª—è—Ä–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–∞—Ö. –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç date –∏–ª–∏ None."""
    if not isinstance(s, str) or not s.strip():
        return None
    s = s.strip()
    fmts = ["%d.%m.%Y", "%Y-%m-%d", "%d-%m-%Y", "%d/%m/%Y"]
    for fmt in fmts:
        try:
            return datetime.strptime(s, fmt).date()
        except Exception:
            pass
    return None


def parse_json_relaxed(s: str) -> dict | None:
    """–ü—ã—Ç–∞–µ–º—Å—è —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å JSON. –ï—Å–ª–∏ –Ω–µ –ø–æ–ª—É—á–∞–µ—Ç—Å—è, –≤—ã—Ä–µ–∑–∞–µ–º —Ñ—Ä–∞–≥–º–µ–Ω—Ç –º–µ–∂–¥—É –ø–µ—Ä–≤–æ–π '{' –∏ –ø–æ—Å–ª–µ–¥–Ω–µ–π '}'."""
    try:
        return json.loads(s)
    except Exception:
        start = s.find("{")
        end = s.rfind("}")
        if start != -1 and end != -1 and end > start:
            try:
                return json.loads(s[start:end + 1])
            except Exception:
                return None
        return None

def render_detailed_checks(parsed: dict):
    """–†–µ–Ω–¥–µ—Ä–∏—Ç –¥–µ—Ç–∞–ª—å–Ω—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ –≤–æ –≤–∫–ª–∞–¥–∫–µ '–î–µ—Ç–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞'."""
    # –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –§–ò–û
    st.markdown("#### –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –§–ò–û")
    client_fio_raw = st.session_state.get("client_fio")
    bedrock_fio_raw = parsed.get("–§–ò–û –∑–∞—è–≤–∏—Ç–µ–ª—è")
    client_fio = norm_name(client_fio_raw)
    bedrock_fio = norm_name(bedrock_fio_raw)
    col1, col2 = st.columns(2)
    with col1:
        st.markdown("**–§–ò–û –∑–∞—è–≤–∏—Ç–µ–ª—è:**")
        st.write(client_fio_raw if client_fio_raw else "‚Äî")
    with col2:
        st.markdown("**–§–ò–û –≤ –¥–æ–∫—É–º–µ–Ω—Ç–µ:**")
        st.write(bedrock_fio_raw if bedrock_fio_raw else "‚Äî")
    if client_fio is None and bedrock_fio is None:
        st.info("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –§–ò–û.")
    elif client_fio is None or bedrock_fio is None:
        st.warning("–û–¥–Ω–æ –∏–∑ –∑–Ω–∞—á–µ–Ω–∏–π –§–ò–û –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç ‚Äî –Ω–µ–≤–æ–∑–º–æ–∂–Ω–æ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ.")
    else:
        if client_fio == bedrock_fio:
            ok = (MIB_RULES.get("–§–ò–û –∑–∞—è–≤–∏—Ç–µ–ª—è –∏ –§–ò–û –≤ –¥–æ–∫—É–º–µ–Ω—Ç–µ –¥–æ–ª–∂–Ω—ã —Å–æ–≤–ø–∞–¥–∞—Ç—å") or {}).get("success")
            st.success(ok or "–§–ò–û —Å–æ–≤–ø–∞–¥–∞–µ—Ç.")
        else:
            err = MIB_ERRORS.get("–§–ò–û –∑–∞—è–≤–∏—Ç–µ–ª—è –∏ –§–ò–û –≤ –¥–æ–∫—É–º–µ–Ω—Ç–µ –¥–æ–ª–∂–Ω—ã —Å–æ–≤–ø–∞–¥–∞—Ç—å")
            if err:
                st.error(f"–ö–æ–¥ –û—à–∏–±–∫–∏ {err['code']}: {err['message']}")
            else:
                st.error("–û—à–∏–±–∫–∞ –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏–∏ –§–ò–û")

    st.divider()
    st.markdown("#### –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Ç–∏–ø–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞")
    client_doc_value = (parsed.get("_client", {}) or {}).get("doc_type_value")
    bedrock_doc_value_raw = parsed.get("–¢–∏–ø –¥–æ–∫—É–º–µ–Ω—Ç–∞")
    client_doc_norm = norm_doc_type(client_doc_value)
    bedrock_doc_norm = norm_doc_type(bedrock_doc_value_raw)
    c1, c2 = st.columns(2)
    with c1:
        st.markdown("**–¢–∏–ø –¥–æ–∫—É–º–µ–Ω—Ç–∞ –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ –∫–ª–∏–µ–Ω—Ç–æ–º:**")
        st.write(f"{client_doc_norm if client_doc_norm else '‚Äî'}")
    with c2:
        st.markdown("**–¢–∏–ø –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞:**")
        st.write(f"{bedrock_doc_norm if bedrock_doc_norm else '‚Äî'}")
    if client_doc_norm is None and bedrock_doc_norm is None:
        st.info("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Ç–∏–ø–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞.")
    elif client_doc_norm is None or bedrock_doc_norm is None:
        st.warning("–û–¥–Ω–æ –∏–∑ –∑–Ω–∞—á–µ–Ω–∏–π —Ç–∏–ø–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç ‚Äî –Ω–µ–≤–æ–∑–º–æ–∂–Ω–æ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ.")
    else:
        if client_doc_norm == bedrock_doc_norm:
            ok = (MIB_RULES.get("–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞") or {}).get("success")
            st.success(ok or "–¢–∏–ø –¥–æ–∫—É–º–µ–Ω—Ç–∞ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥—ë–Ω.")
        else:
            err = MIB_ERRORS.get("–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞")
            if err:
                st.error(f"–ö–æ–¥ –û—à–∏–±–∫–∏ {err['code']}: {err['message']}")
            else:
                st.error("–û—à–∏–±–∫–∞ –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Ç–∏–ø–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞")

    st.divider()
    st.markdown("#### –ê–∫—Ç—É–∞–ª—å–Ω–æ—Å—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç–∞")
    # –¢–µ–∫—É—â–∞—è –¥–∞—Ç–∞
    today = datetime.utcnow().date()
    # –°—Ä–æ–∫ –∞–∫—Ç—É–∞–ª—å–Ω–æ—Å—Ç–∏ –ø–æ —Ç–∏–ø—É
    doc_type_for_validity = bedrock_doc_norm or client_doc_norm
    validity_days = VALIDITY_DAYS.get(doc_type_for_validity) if doc_type_for_validity else None
    issue_date_raw = parsed.get("–î–∞—Ç–∞ –≤—ã–¥–∞—á–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞")
    issue_date = parse_date_safe(issue_date_raw)
    expires_date = None
    if isinstance(validity_days, int) and issue_date is not None:
        expires = issue_date.toordinal() + validity_days
        expires_date = datetime.fromordinal(expires).date()
    validity_rows = [
        {"–ü–æ–ª–µ": "–ê–∫—Ç—É–∞–ª—å–Ω–∞—è –¥–∞—Ç–∞", "–ó–Ω–∞—á–µ–Ω–∏–µ": format_date_ddmmyyyy(today)},
        {"–ü–æ–ª–µ": "–°—Ä–æ–∫ –∞–∫—Ç—É–∞–ª—å–Ω–æ—Å—Ç–∏", "–ó–Ω–∞—á–µ–Ω–∏–µ": (f"{doc_type_for_validity} {validity_days} –∫–∞–ª. –¥–Ω–µ–π" if validity_days is not None and doc_type_for_validity else "‚Äî")},
        {"–ü–æ–ª–µ": "–î–∞—Ç–∞ –≤—ã–¥–∞—á–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞", "–ó–Ω–∞—á–µ–Ω–∏–µ": format_date_ddmmyyyy(issue_date_raw)},
        {"–ü–æ–ª–µ": "–î–µ–π—Å—Ç–≤–∏—Ç–µ–ª–µ–Ω –¥–æ (–≤–∫–ª—é—á–∏—Ç–µ–ª—å–Ω–æ)", "–ó–Ω–∞—á–µ–Ω–∏–µ": (format_date_ddmmyyyy(expires_date) if expires_date else "‚Äî")},
    ]
    _df_validity = pd.DataFrame(validity_rows)
    try:
        st.table(_df_validity.style.hide(axis="index"))
    except Exception:
        st.table(_df_validity.reset_index(drop=True))
    if validity_days is None:
        st.info("–¢–∏–ø –¥–æ–∫—É–º–µ–Ω—Ç–∞ –Ω–µ–∏–∑–≤–µ—Å—Ç–µ–Ω ‚Äî –Ω–µ–≤–æ–∑–º–æ–∂–Ω–æ –æ—Ü–µ–Ω–∏—Ç—å –∞–∫—Ç—É–∞–ª—å–Ω–æ—Å—Ç—å.")
    elif issue_date is None:
        st.warning("–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å –¥–∞—Ç—É –≤—ã–¥–∞—á–∏ ‚Äî –Ω–µ–≤–æ–∑–º–æ–∂–Ω–æ –æ—Ü–µ–Ω–∏—Ç—å –∞–∫—Ç—É–∞–ª—å–Ω–æ—Å—Ç—å.")
    elif expires_date is not None:
        if today <= expires_date:
            ok = (MIB_RULES.get("–ê–∫—Ç—É–∞–ª—å–Ω–∞—è –¥–∞—Ç–∞") or {}).get("success")
            st.success(ok or "–î–æ–∫—É–º–µ–Ω—Ç –≤ –ø—Ä–µ–¥–µ–ª–∞—Ö —Å—Ä–æ–∫–∞ –∞–∫—Ç—É–∞–ª—å–Ω–æ—Å—Ç–∏.")
        else:
            err = MIB_ERRORS.get("–ê–∫—Ç—É–∞–ª—å–Ω–∞—è –¥–∞—Ç–∞")
            if err:
                st.error(f"–ö–æ–¥ –û—à–∏–±–∫–∏ {err['code']}: {err['message']}")
            else:
                st.error("–î–æ–∫—É–º–µ–Ω—Ç –Ω–µ –∞–∫—Ç—É–∞–ª–µ–Ω")

    st.divider()
    st.markdown("#### –ù–∞–ª–∏—á–∏–µ –ø–µ—á–∞—Ç–∏ –∏–ª–∏ QR")
    si = parsed.get("_stamps") if isinstance(parsed.get("_stamps"), dict) else {}
    sp = si.get("stamp_present")
    sc = si.get("stamp_confidence")
    qp = si.get("qr_present")
    qc = si.get("qr_confidence")
    if sp is True or qp is True:
        ok = (MIB_RULES.get("–ù–∞–ª–∏—á–∏–µ QR –∏–ª–∏ –ø–µ—á–∞—Ç–∏") or {}).get("success")
        st.success(ok or "–û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –ø–µ—á–∞—Ç—å –∏/–∏–ª–∏ QR.")
    elif sp is False and qp is False:
        err = MIB_ERRORS.get("–ù–∞–ª–∏—á–∏–µ QR –∏–ª–∏ –ø–µ—á–∞—Ç–∏")
        if err:
            st.error(f"–ö–æ–¥ –û—à–∏–±–∫–∏ {err['code']}: {err['message']}")
        else:
            st.error("–ù–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω—ã –Ω–∏ –ø–µ—á–∞—Ç—å, –Ω–∏ QR")
    else:
        st.info("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –Ω–∞–ª–∏—á–∏—è –ø–µ—á–∞—Ç–∏/QR.")
    colp, colq = st.columns(2)
    with colp:
        st.markdown("**–ü–µ—á–∞—Ç—å:**")
        if sp is True:
            msg = "–æ–±–Ω–∞—Ä—É–∂–µ–Ω–∞"
            if isinstance(sc, (int, float)):
                msg += f" (CR {round(sc)}%)"
            st.write(msg)
        elif sp is False:
            st.write("–Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∞")
        else:
            st.write("–Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–æ")
    with colq:
        st.markdown("**QR-–∫–æ–¥:**")
        if qp is True:
            msg = "–æ–±–Ω–∞—Ä—É–∂–µ–Ω"
            if isinstance(qc, (int, float)):
                msg += f" (CR {round(qc)}%)"
            st.write(msg)
        elif qp is False:
            st.write("–Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω")
        else:
            st.write("–Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–æ")

    st.divider()
    st.markdown("#### –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Å—Ç—Ä–∞–Ω–∏—Ü –¥–æ–∫—É–º–µ–Ω—Ç–∞")
    _is_pdf_flag = st.session_state.get("last_is_pdf")
    if _is_pdf_flag:
        _pc = st.session_state.get("pdf_page_count")
        if isinstance(_pc, int):
            st.write(f"–°—Ç—Ä–∞–Ω–∏—Ü –≤ –ø—Ä–∏–∫—Ä–µ–ø–ª–µ–Ω–Ω–æ–º —Ñ–∞–π–ª–µ: {_pc}")
            if _pc == 1:
                ok = (MIB_RULES.get("–ü—Ä–∏–∫—Ä–µ–ø–ª–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å –æ–¥–∏–Ω –¥–æ–∫—É–º–µ–Ω—Ç") or {}).get("success")
                st.success(ok or "–ü—Ä–∏–∫—Ä–µ–ø–ª–µ–Ω–Ω—ã–π —Ñ–∞–π–ª —Å–æ–¥–µ—Ä–∂–∏—Ç –æ–¥–∏–Ω –¥–æ–∫—É–º–µ–Ω—Ç")
            elif _pc > 1:
                err = MIB_ERRORS.get("–ü—Ä–∏–∫—Ä–µ–ø–ª–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å –æ–¥–∏–Ω –¥–æ–∫—É–º–µ–Ω—Ç")
                if err:
                    st.error(f"–ö–æ–¥ –û—à–∏–±–∫–∏ {err['code']}: {err['message']}")
                else:
                    st.error("–ü—Ä–∏–∫—Ä–µ–ø–ª–µ–Ω–Ω—ã–π —Ñ–∞–π–ª —Å–æ–¥–µ—Ä–∂–∏—Ç –±–æ–ª–µ–µ –æ–¥–Ω–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞")
            else:
                st.info("–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–∞–Ω–∏—Ü –≤ –ø—Ä–∏–∫—Ä–µ–ø–ª–µ–Ω–Ω–æ–º —Ñ–∞–π–ª–µ.")
        else:
            st.info("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–∞–Ω–∏—Ü –≤ –ø—Ä–∏–∫—Ä–µ–ø–ª–µ–Ω–Ω–æ–º —Ñ–∞–π–ª–µ –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ.")
    else:
        st.caption("–ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–∏–º–µ–Ω—è–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –∫ PDF-—Ñ–∞–π–ª–∞–º. –î–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π (JPG/JPEG) –Ω–µ –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è.")

# --- –ö–∞—Å—Ç–æ–º–∏–∑–∞—Ü–∏—è –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞ ---\
st.markdown("""
<style>
.block-container{max-width:980px;padding-top:1.25rem;}
.meta{color:#6b7280;font-size:0.92rem;margin:0.25rem 0 1rem 0;}
.meta code{background:#f3f4f6;border:1px solid #e5e7eb;padding:2px 6px;border-radius:6px;}
.card{border:1px solid #e5e7eb;border-radius:14px;background:#ffffff;box-shadow:0 2px 8px rgba(0,0,0,.04);} 
.card.pad{padding:22px;}
.result-card{border:1px solid #e5e7eb;border-radius:14px;padding:16px;background:#fafafa;}
.stButton>button{border-radius:10px;padding:.65rem 1rem;font-weight:600;}
.stDownloadButton>button{border-radius:10px;}
</style>
""", unsafe_allow_html=True)

# with st.expander("–ü–æ–º–æ—â—å –∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞", expanded=False):
#     tabs = st.tabs(["–ó–∞–ø—É—Å–∫ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è", "–°–æ–∑–¥–∞–Ω–∏–µ Access Key", "–û–∫—Ä—É–∂–µ–Ω–∏–µ"])
#     with tabs[0]:
#         st.markdown("#### 1) –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ AWS CLI v2")
#         st.code('''curl "https://awscli.amazonaws.com/AWSCLIV2.pkg" -o "AWSCLIV2.pkg"\nsudo installer -pkg AWSCLIV2.pkg -target /''', language="bash")
#         st.code("aws --version", language="bash")
#         st.markdown("#### 2) –ù–∞—Å—Ç—Ä–æ–π—Ç–µ —É—á—ë—Ç–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ")
#         st.code("aws configure", language="bash")
#         st.markdown("#### 3) –ó–∞–ø—É—Å—Ç–∏—Ç–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ")
#         st.code("streamlit run main.py", language="bash")
#     with tabs[1]:
#         st.markdown("### üîë –°–æ–∑–¥–∞–Ω–∏–µ Access Key (CLI)")
#         st.markdown("–ü—Ä–æ–≥—Ä–∞–º–º–Ω—ã–µ –∫–ª—é—á–∏ –Ω—É–∂–Ω—ã –¥–ª—è —Ä–∞–±–æ—Ç—ã –∏–∑ –∫–æ–¥–∞/CLI. –°–æ–∑–¥–∞–π—Ç–µ –∏—Ö –≤ AWS IAM.")
#     with tabs[2]:
#         st.markdown("### –û–∫—Ä—É–∂–µ–Ω–∏–µ")
#         st.markdown(f"- Bucket: `{BUCKET_NAME}`\n- Region: `{AWS_REGION}`\n- Model: `{MODEL_ID}`")
#         # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ Inference Profile —á–µ—Ä–µ–∑ UI / ENV
#         default_ip = (
#             os.getenv("BEDROCK_INFERENCE_PROFILE")
#             or DEFAULT_INFERENCE_PROFILE_ARN
#             or DEFAULT_INFERENCE_PROFILE_ID
#         )
#         ip_value = st.text_input(
#             "Inference Profile (ID –∏–ª–∏ ARN –¥–ª—è Claude 3.7 Sonnet)",
#             value=st.session_state.get("inference_profile", default_ip),
#             help="–ù–∞–ø—Ä–∏–º–µ—Ä ID: us.anthropic.claude-3-7-sonnet-20250219-v1:0 –∏–ª–∏ ARN: arn:aws:bedrock:...:inference-profile/us.anthropic.claude-3-7-sonnet-20250219-v1:0",
#         )
#         st.session_state["inference_profile"] = ip_value.strip() if ip_value else ""

# --- –§–æ—Ä–º–∞ –∑–∞–≥—Ä—É–∑–∫–∏ ---
with st.form("upload_form", clear_on_submit=False):
    fio = st.text_input(
        "–§–ò–û –∑–∞—è–≤–∏—Ç–µ–ª—è",
        value=st.session_state.get("client_fio", ""),
        help="–í–≤–µ–¥–∏—Ç–µ –ø–æ–ª–Ω–æ—Å—Ç—å—é: –§–∞–º–∏–ª–∏—è –ò–º—è –û—Ç—á–µ—Å—Ç–≤–æ"
    )
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –µ–¥–∏–Ω—ã–π –∏—Å—Ç–æ—á–Ω–∏–∫ –ø—Ä–∞–≤–¥—ã –¥–ª—è –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ –∏ –º–∞–ø–ø–∏–Ω–≥–∞
    doc_type_options = DOC_TYPE_OPTIONS
    doc_type = st.selectbox(
        "–¢–∏–ø –¥–æ–∫—É–º–µ–Ω—Ç–∞",
        options=["–í—ã–±–µ—Ä–∏—Ç–µ —Ç–∏–ø –¥–æ–∫—É–º–µ–Ω—Ç–∞"] + doc_type_options,
        index=0,
        help="–í—ã–±–µ—Ä–∏—Ç–µ –æ–¥–∏–Ω –¥–æ–∫—É–º–µ–Ω—Ç, –∫–æ—Ç–æ—Ä—ã–π –≤—ã –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç–µ"
    )
    uploaded_file = st.file_uploader(
        "–í—ã–±–µ—Ä–∏—Ç–µ –¥–æ–∫—É–º–µ–Ω—Ç (1 —Ñ–∞–π–ª)",
        type=["pdf", "jpg"],
        accept_multiple_files=False,
        help="–ü–æ–¥–¥–µ—Ä–∂–∫–∞: PDF, JPEG. –†–∞–∑—Ä–µ—à–µ–Ω–∞ –∑–∞–≥—Ä—É–∑–∫–∞ —Ç–æ–ª—å–∫–æ –æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞.",
    )
    submitted = st.form_submit_button("–ó–∞–≥—Ä—É–∑–∏—Ç—å –∏ –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å", type="primary")


# ===================== –§–£–ù–ö–¶–ò–ò ============================

def get_s3_client(profile, region_name):
    if profile:
        session = boto3.session.Session(profile_name=profile, region_name=region_name or None)
        return session.client("s3")
    return boto3.client("s3", region_name=region_name or None)

def get_next_upload_folder(s3_client, bucket, prefix):
    try:
        paginator = s3_client.get_paginator("list_objects_v2")
        existing_max = 0
        for page in paginator.paginate(Bucket=bucket, Prefix=prefix, Delimiter="/"):
            for cp in page.get("CommonPrefixes", []) or []:
                p = cp.get("Prefix", "")
                m = re.search(r"upload_id_(\d{3,})/\Z", p)
                if m:
                    existing_max = max(existing_max, int(m.group(1)))
        next_id = existing_max + 1
        return f"{prefix}upload_id_{next_id:03d}/"
    except Exception:
        ts = datetime.utcnow().strftime("%Y%m%d-%H%M%S")
        return f"{prefix}upload_id_{ts}/"

def textract_blocks_to_text(tex_resp: dict) -> str:
    lines = [b.get("Text", "") for b in tex_resp.get("Blocks", []) if b.get("BlockType") == "LINE"]
    return "\n".join([ln for ln in lines if ln])

# --- –û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –ø–æ–¥–ø–∏—Å–µ–π (Textract SIGNATURES) —Å backoff ---
def detect_signatures(textract_client, bucket: str, key: str, content_type: str):
    results = []
    try:
        is_pdf = ("pdf" in (content_type or "").lower()) or key.lower().endswith(".pdf")
        if not is_pdf:
            s3 = boto3.client("s3")
            obj = s3.get_object(Bucket=bucket, Key=key)
            img_bytes = obj["Body"].read()
            resp = textract_client.analyze_document(Document={"Bytes": img_bytes}, FeatureTypes=["SIGNATURES"])
            for b in resp.get("Blocks", []) or []:
                if b.get("BlockType") == "SIGNATURE":
                    results.append({"confidence": b.get("Confidence"), "geometry": b.get("Geometry"), "page": b.get("Page")})
        else:
            start = textract_client.start_document_analysis(
                DocumentLocation={"S3Object": {"Bucket": bucket, "Name": key}},
                FeatureTypes=["SIGNATURES"],
            )
            job_id = start["JobId"]
            pages = []

            # Backoff —Ñ—É–Ω–∫—Ü–∏—è —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –ø–∞–≥–∏–Ω–∞—Ü–∏–∏ —á–µ—Ä–µ–∑ NextToken
            def get_document_analysis_with_backoff(job_id, next_token=None, max_retries=6):
                retries = 0
                while True:
                    try:
                        params = {"JobId": job_id, "MaxResults": 1000}
                        if next_token:
                            params["NextToken"] = next_token
                        resp = textract_client.get_document_analysis(**params)
                        return resp
                    except ClientError as e:
                        if e.response['Error']['Code'] == "ThrottlingException":
                            wait = (2 ** retries) + random.random()
                            time.sleep(wait)
                            retries += 1
                            if retries > max_retries:
                                raise Exception("–ü—Ä–µ–≤—ã—à–µ–Ω–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ø—ã—Ç–æ–∫ –∏–∑-–∑–∞ ThrottlingException")
                        else:
                            raise

            while True:
                resp = get_document_analysis_with_backoff(job_id, next_token=None)
                status = resp["JobStatus"]
                if status == "SUCCEEDED":
                    pages.append(resp)
                    next_token = resp.get("NextToken")
                    while next_token:
                        nxt = get_document_analysis_with_backoff(job_id, next_token=next_token)
                        pages.append(nxt)
                        next_token = nxt.get("NextToken")
                    break
                elif status == "FAILED":
                    raise Exception("Textract –∞–Ω–∞–ª–∏–∑ –Ω–µ —É–¥–∞–ª—Å—è")
                else:
                    time.sleep(2 + random.random())

            for page in pages:
                for b in page.get("Blocks", []) or []:
                    if b.get("BlockType") == "SIGNATURE":
                        results.append({"confidence": b.get("Confidence"), "geometry": b.get("Geometry"), "page": b.get("Page")})

    except Exception as e:
        return {"signatures": [], "error": str(e)}
    return {"signatures": results, "error": None}

def _b64_image_from_bytes(img_bytes: bytes, media_type: str) -> dict:
    return {
        "type": "image",
        "source": {
            "type": "base64",
            "media_type": media_type,
            "data": base64.b64encode(img_bytes).decode("utf-8"),
        },
    }

def detect_stamp_llm(bedrock_client, model_id: str, images: list[dict]):
    """
    images: —Å–ø–∏—Å–æ–∫ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ content –¥–ª—è Anthropic messages API –≤–∏–¥–∞
      {"type":"image", "source": {"type":"base64","media_type":"image/png","data":"..."}}
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç: {"present": bool|None, "confidence": float|None, "reason": str|None, "raw": str, "error": None|str}
    """
    try:
        instruction = (
            "–û–ø—Ä–µ–¥–µ–ª–∏, –µ—Å—Ç—å –ª–∏ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏ –æ—Ç—Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞: "
            "1) –ø–µ—á–∞—Ç—å (—à—Ç–∞–º–ø: –∫—Ä—É–≥–ª–∞—è –∏–ª–∏ –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω–∞—è), "
            "2) QR-–∫–æ–¥ (–∫–≤–∞–¥—Ä–∞—Ç–Ω—ã–π –º–∞—Ç—Ä–∏—á–Ω—ã–π –∫–æ–¥)."
        )
        format_req = (
            "–í–µ—Ä–Ω–∏ —Å—Ç—Ä–æ–≥–æ JSON –±–µ–∑ –ø–æ—è—Å–Ω–µ–Ω–∏–π:\n"
            "{\n"
            "  \"stamp_present\": true|false,\n"
            "  \"stamp_confidence\": number (0..100),\n"
            "  \"qr_present\": true|false,\n"
            "  \"qr_confidence\": number (0..100),\n"
            "}"
        )
        body = {
            "anthropic_version": "bedrock-2023-05-31",
            "max_tokens": 256,
            "temperature": 0,
            "messages": [
                {
                    "role": "user",
                    "content": ([{"type": "text", "text": instruction + "\n" + format_req}] + images),
                }
            ],
        }
        data = _invoke_with_inference_profile(bedrock_client, body, model_id=model_id)
        text = data.get("content", [{}])[0].get("text", "")
        # –ü–æ–ø—ã—Ç–∫–∞ —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å JSON –∏–∑ –æ—Ç–≤–µ—Ç–∞
        parsed = None
        try:
            parsed = json.loads(text)
        except Exception:
            s = text.find("{")
            e = text.rfind("}")
            if s != -1 and e != -1 and e > s:
                try:
                    parsed = json.loads(text[s:e+1])
                except Exception:
                    parsed = None
        if not isinstance(parsed, dict):
            return {"stamp_present": None, "stamp_confidence": None, "qr_present": None, "qr_confidence": None, "raw": text, "error": "LLM returned non-JSON"}
        return {
            # –°—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –ø–æ–ª—è (—Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å)
            "stamp_present": parsed.get("stamp_present"),
            "stamp_confidence": parsed.get("stamp_confidence"),
            "qr_present": parsed.get("qr_present"),
            "qr_confidence": parsed.get("qr_confidence"),
            # –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –ø–æ–ª—è
            "raw": text,
            "error": None,
        }
    except Exception as e:
        return {"present": None, "confidence": None, "reason": None, "raw": "", "error": str(e)}

def convert_pdf_to_images_and_store(s3_client, bucket: str, key: str, max_pages: int = 3, zoom: float = 2.0):
    """
    –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –ø–µ—Ä–≤—ã—Ö max_pages —Å—Ç—Ä–∞–Ω–∏—Ü PDF (–∏–∑ S3) –≤ PNG –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è.
    –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –ª–æ–∫–∞–ª—å–Ω–æ –≤ /tmp –∏ –∑–∞–≥—Ä—É–∂–∞–µ—Ç –≤ S3 –ø–æ –ø—É—Ç–∏ previews/page_XXX.png.

    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç dict: {"local_paths": [..], "s3_keys": [..], "page_count": int, "error": None|str}
    """
    if fitz is None:
        return {"local_paths": [], "s3_keys": [], "error": "PyMuPDF (fitz) –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω"}
    try:
        obj = s3_client.get_object(Bucket=bucket, Key=key)
        pdf_bytes = obj["Body"].read()

        doc = fitz.open(stream=pdf_bytes, filetype="pdf")
        total_pages = len(doc)
        pages = min(total_pages, max_pages)
        local_paths = []
        s3_keys = []
        tmp_dir = tempfile.mkdtemp(prefix="pdf_previews_")

        # –ü—Ä–µ—Ñ–∏–∫—Å –¥–ª—è S3 (—Ç–æ—Ç –∂–µ –∫–∞—Ç–∞–ª–æ–≥, —á—Ç–æ –∏ —É –∏—Å—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞)
        folder = key.rsplit("/", 1)[0] + "/" if "/" in key else ""
        previews_prefix = f"{folder}previews/"

        mat = fitz.Matrix(zoom, zoom)
        for i in range(pages):
            page = doc.load_page(i)
            pix = page.get_pixmap(matrix=mat, colorspace=fitz.csRGB, alpha=False)
            local_path = os.path.join(tmp_dir, f"page_{i+1:03d}.png")
            pix.save(local_path)
            local_paths.append(local_path)

            preview_key = f"{previews_prefix}page_{i+1:03d}.png"
            with open(local_path, "rb") as f:
                s3_client.upload_fileobj(
                    Fileobj=f,
                    Bucket=bucket,
                    Key=preview_key,
                    ExtraArgs={"ContentType": "image/png"},
                )
            s3_keys.append(preview_key)

        return {"local_paths": local_paths, "s3_keys": s3_keys, "page_count": total_pages, "error": None}
    except Exception as e:
        return {"local_paths": [], "s3_keys": [], "page_count": 0, "error": str(e)}

def build_prompt_russian(extracted_text: str) -> str:
    instruction = (
        "–ò–∑–≤–ª–µ–∫–∏ —Å–ª–µ–¥—É—é—â—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ —Ç–µ–∫—Å—Ç–∞.\n"
        "–í–µ—Ä–Ω–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å—Ç—Ä–æ–≥–æ –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON:\n"
        "{\n"
        "  \"–§–ò–û –∑–∞—è–≤–∏—Ç–µ–ª—è\": string | null,\n"
        "  \"–¢–∏–ø –¥–æ–∫—É–º–µ–Ω—Ç–∞\": \"–õ–∏—Å—Ç\" | \"–ü—Ä–∏–∫–∞–∑\" | \"–°–ø—Ä–∞–≤–∫–∞\" | null,\n"
        "  \"–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞\": string | null,\n"
        "  \"–î–∞—Ç–∞ –≤—ã–¥–∞—á–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞\": string | null,\n"
        "  \"–î–∞—Ç–∞ –Ω–∞—á–∞–ª–∞ –æ—Ç–ø—É—Å–∫–∞\": string | null,\n"
        "  \"–î–∞—Ç–∞ –æ–∫–æ–Ω—á–∞–Ω–∏—è –æ—Ç–ø—É—Å–∫–∞\": string | null\n"
        "}\n\n"
        "–ü—Ä–∞–≤–∏–ª–∞ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –ø–æ–ª—è '–¢–∏–ø –¥–æ–∫—É–º–µ–Ω—Ç–∞':\n"
        "- –ï—Å–ª–∏ '–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞' —Å–æ–¥–µ—Ä–∂–∏—Ç '–õ–∏—Å—Ç –≤—Ä–µ–º–µ–Ω–Ω–æ–π –Ω–µ—Ç—Ä—É–¥–æ—Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏', —Ç–æ '–¢–∏–ø –¥–æ–∫—É–º–µ–Ω—Ç–∞' = '–õ–∏—Å—Ç'.\n"
        "- –ï—Å–ª–∏ '–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞' —Å–æ–¥–µ—Ä–∂–∏—Ç '–ü—Ä–∏–∫–∞–∑', —Ç–æ '–¢–∏–ø –¥–æ–∫—É–º–µ–Ω—Ç–∞' = '–ü—Ä–∏–∫–∞–∑'.\n"
        "- –ï—Å–ª–∏ '–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞' —Å–æ–¥–µ—Ä–∂–∏—Ç '–°–ø—Ä–∞–≤–∫–∞', —Ç–æ '–¢–∏–ø –¥–æ–∫—É–º–µ–Ω—Ç–∞' = '–°–ø—Ä–∞–≤–∫–∞'.\n"
        "- –ï—Å–ª–∏ –Ω–µ–≤–æ–∑–º–æ–∂–Ω–æ –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å, —Ç–æ '–¢–∏–ø –¥–æ–∫—É–º–µ–Ω—Ç–∞' = null.\n\n"
        "–¢–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞:\n"
    )


    return instruction + extracted_text

def get_bedrock_client(profile: str | None, region_name: str | None):
    if profile:
        session = boto3.session.Session(profile_name=profile, region_name=region_name or None)
        return session.client("bedrock-runtime")
    return boto3.client("bedrock-runtime", region_name=region_name or None)

def _get_inference_profile_from_state() -> str | None:
    # –ü–æ—Ä—è–¥–æ–∫ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞: UI state -> ENV -> defaults
    ip = (
        st.session_state.get("inference_profile")
        or os.getenv("BEDROCK_INFERENCE_PROFILE")
        or DEFAULT_INFERENCE_PROFILE_ARN
        or DEFAULT_INFERENCE_PROFILE_ID
    )
    return ip

def _invoke_with_inference_profile(client, body: dict, model_id: str):
    payload = json.dumps(body)
    ip = _get_inference_profile_from_state()
    # –í —Ç–µ–∫—É—â–µ–π –≤–µ—Ä—Å–∏–∏ SDK –ø—Ä–æ—Ñ–∏–ª—å –ø–µ—Ä–µ–¥–∞—ë—Ç—Å—è –≤ modelId (ID/ARN –ø—Ä–æ—Ñ–∏–ª—è),
    # —Ç–∞–∫ –∫–∞–∫ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã inferenceProfileArn/Id –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è.
    target_model_id = (ip.strip() if ip else model_id)
    resp = client.invoke_model(
        modelId=target_model_id,
        contentType="application/json",
        accept="application/json",
        body=payload,
    )
    return json.loads(resp["body"].read())

def call_bedrock_invoke(model_id: str, prompt: str, client):
    if model_id.startswith("anthropic."):
        body = {
            "anthropic_version": "bedrock-2023-05-31",
            "max_tokens": 1024,
            "temperature": 0,
            "messages": [{"role": "user", "content": [{"type": "text", "text": prompt}]}],
        }
        data = _invoke_with_inference_profile(client, body, model_id=model_id)
        return data.get("content", [{}])[0].get("text", "")
    else:
        body = {"inputText": prompt, "textGenerationConfig": {"maxTokenCount": 1024, "temperature": 0}}
        data = _invoke_with_inference_profile(client, body, model_id=model_id)
        if "results" in data and data["results"]:
            return data["results"][0].get("outputText", "")
        return json.dumps(data)

# =============== –û–°–ù–û–í–ù–û–ô –ü–†–û–¶–ï–°–° =========================
if submitted:
    if not BUCKET_NAME:
        st.error("S3-–±–∞–∫–µ—Ç –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω.")
    elif not (fio and fio.strip()):
        st.error("–£–∫–∞–∂–∏—Ç–µ –§–ò–û –∑–∞—è–≤–∏—Ç–µ–ª—è.")
    elif doc_type == "–í—ã–±–µ—Ä–∏—Ç–µ —Ç–∏–ø –¥–æ–∫—É–º–µ–Ω—Ç–∞":
        st.error("–í—ã–±–µ—Ä–∏—Ç–µ —Ç–∏–ø –¥–æ–∫—É–º–µ–Ω—Ç–∞.")
    elif not uploaded_file:
        st.error("–ù–µ –≤—ã–±—Ä–∞–Ω —Ñ–∞–π–ª –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏.")
    else:
        # –°–æ—Ö—Ä–∞–Ω–∏–º –∑–Ω–∞—á–µ–Ω–∏—è —Ñ–æ—Ä–º—ã –≤ —Å–µ—Å—Å–∏—é
        st.session_state["client_fio"] = fio.strip()
        st.session_state["client_doc_type"] = doc_type
        try:
            s3 = get_s3_client(AWS_PROFILE.strip() or None, AWS_REGION)
            progress = st.progress(0)

            original_name = uploaded_file.name
            base_prefix = (KEY_PREFIX or "").strip() or "uploads/"
            if base_prefix and not base_prefix.endswith("/"):
                base_prefix += "/"

            upload_folder = get_next_upload_folder(s3, BUCKET_NAME, base_prefix)
            key = f"{upload_folder}{original_name}"

            uploaded_file.seek(0)
            content_type = getattr(uploaded_file, "type", None) or "application/octet-stream"
            with st.status("–ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞...", expanded=False) as status:
                s3.upload_fileobj(
                    Fileobj=uploaded_file,
                    Bucket=BUCKET_NAME,
                    Key=key,
                    ExtraArgs={"ContentType": content_type},
                )
                s3_uri = f"s3://{BUCKET_NAME}/{key}"
                status.update(label=f"–§–∞–π–ª –∑–∞–≥—Ä—É–∂–µ–Ω –≤ {s3_uri}", state="complete")
            progress.progress(30)

            
            # st.success(f"–§–∞–π–ª —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω –≤ {s3_uri}")

            st.session_state["last_s3_bucket"] = BUCKET_NAME
            st.session_state["last_s3_key"] = key
            st.session_state["last_s3_uri"] = s3_uri

            try:
                with st.status("–û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞...", expanded=False) as status:
                    status.update(label="–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ —á–µ—Ä–µ–∑ Textract...", state="running")
                    if AWS_PROFILE.strip():
                        session = boto3.session.Session(profile_name=AWS_PROFILE.strip(), region_name=AWS_REGION)
                        textract = session.client("textract")
                    else:
                        textract = boto3.client("textract", region_name=AWS_REGION)

                    # –ï—Å–ª–∏ –∑–∞–≥—Ä—É–∂–µ–Ω PDF, —Å–æ–∑–¥–∞–¥–∏–º –ø—Ä–µ–≤—å—é –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏ —Å–æ—Ö—Ä–∞–Ω–∏–º –ª–æ–∫–∞–ª—å–Ω–æ –∏ –≤ S3
                    is_pdf = ("pdf" in (content_type or "").lower()) or key.lower().endswith(".pdf")
                    # –°–æ—Ö—Ä–∞–Ω–∏–º —Ñ–ª–∞–≥ –¥–ª—è –≤–∫–ª–∞–¥–∫–∏ –ø—Ä–æ–≤–µ—Ä–∫–∏
                    st.session_state["last_is_pdf"] = bool(is_pdf)
                    pdf_previews = None
                    if is_pdf:
                        status.update(label="–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è PDF –≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è...", state="running")
                        pdf_previews = convert_pdf_to_images_and_store(s3, BUCKET_NAME, key, max_pages=3, zoom=2.0)
                        st.session_state["pdf_previews"] = pdf_previews
                        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —á–∏—Å–ª–æ —Å—Ç—Ä–∞–Ω–∏—Ü PDF –ø—Ä–∏ –Ω–∞–ª–∏—á–∏–∏
                        if isinstance(pdf_previews, dict) and "page_count" in pdf_previews:
                            st.session_state["pdf_page_count"] = pdf_previews.get("page_count")

                    tex_resp = textract.detect_document_text(Document={"S3Object": {"Bucket": BUCKET_NAME, "Name": key}})
                    progress.progress(60)

                    # –ü–æ–¥–ø–∏—Å–∏ –∏ –ø–µ—á–∞—Ç–∏
                    signature_hits = detect_signatures(textract, BUCKET_NAME, key, content_type)
                    # LLM –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–µ—á–∞—Ç–∏ (–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: –ø—Ä–µ–≤—å—é —Å—Ç—Ä–∞–Ω–∏—Ü PDF –∏–ª–∏ —Å–∞–º–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è JPEG)
                    stamp_hits = {"stamp_present": None, "stamp_confidence": None, "qr_present": None, "qr_confidence": None, "raw": "", "error": None}
                    try:
                        bedrock = get_bedrock_client(AWS_PROFILE.strip() or None, BEDROCK_REGION)
                        imgs_content = []
                        if is_pdf and st.session_state.get("pdf_previews") and st.session_state["pdf_previews"].get("local_paths"):
                            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ª–æ–∫–∞–ª—å–Ω—ã–µ PNG –ø—Ä–µ–≤—å—é
                            for lp in st.session_state["pdf_previews"]["local_paths"][:3]:
                                with open(lp, "rb") as f:
                                    imgs_content.append(_b64_image_from_bytes(f.read(), "image/png"))
                        else:
                            # –î–ª—è JPEG: –±–µ—Ä—ë–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –æ–±—ä–µ–∫—Ç –∏–∑ S3
                            if ("jpeg" in content_type.lower()) or ("jpg" in content_type.lower()) or key.lower().endswith((".jpg",".jpeg")):
                                obj = s3.get_object(Bucket=BUCKET_NAME, Key=key)
                                bts = obj["Body"].read()
                                imgs_content.append(_b64_image_from_bytes(bts, "image/jpeg"))
                        if imgs_content:
                            stamp_llm = detect_stamp_llm(bedrock, MODEL_ID, imgs_content)
                            stamp_hits = stamp_llm
                    except Exception as e:
                        stamp_hits = {"stamp_present": None, "stamp_confidence": None, "qr_present": None, "qr_confidence": None, "raw": "", "error": str(e)}

                    status.update(label="–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø–æ–ª–µ–π —á–µ—Ä–µ–∑ Bedrock...", state="running")
                    extracted_text = textract_blocks_to_text(tex_resp)[:15000]
                    bedrock = get_bedrock_client(AWS_PROFILE.strip() or None, BEDROCK_REGION)
                    prompt = build_prompt_russian(extracted_text)
                    model_output = call_bedrock_invoke(MODEL_ID, prompt, bedrock)
                    progress.progress(90)

                    parsed = parse_json_relaxed(model_output)
                    if parsed is None:
                        parsed = {"–û—à–∏–±–∫–∞": "LLM –≤–µ—Ä–Ω—É–ª –Ω–µ–≤–∞–ª–∏–¥–Ω—ã–π JSON"}

                    # –î–æ–±–∞–≤–∏–º —Å–≤–µ–¥–µ–Ω–∏—è, –≤–≤–µ–¥—ë–Ω–Ω—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º, –≤ –∏—Ç–æ–≥–æ–≤—ã–π JSON
                    parsed["_client"] = {
                        "fio": st.session_state.get("client_fio"),
                        "doc_type": st.session_state.get("client_doc_type"),
                        # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–æ—Ç–∫–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–π —Å–≤–µ—Ä–∫–∏ —Å –æ—Ç–≤–µ—Ç–∞–º–∏ Bedrock
                        "doc_type_value": DOC_TYPE_VALUE_MAP.get(st.session_state.get("client_doc_type")),
                    }

                    parsed["_signatures"] = signature_hits
                    parsed["_stamps"] = stamp_hits

                    # --- –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø—Ä–æ–≤–µ—Ä–æ–∫ –≤ JSON (_checks) ---
                    try:
                        checks = {}
                        # –§–ò–û
                        checks["fio_match"] = (norm_name(st.session_state.get("client_fio")) == norm_name(parsed.get("–§–ò–û –∑–∞—è–≤–∏—Ç–µ–ª—è")))
                        # –¢–∏–ø –¥–æ–∫—É–º–µ–Ω—Ç–∞
                        client_dt_norm = norm_doc_type(DOC_TYPE_VALUE_MAP.get(st.session_state.get("client_doc_type")))
                        bedrock_dt_norm = norm_doc_type(parsed.get("–¢–∏–ø –¥–æ–∫—É–º–µ–Ω—Ç–∞"))
                        checks["doc_type_match"] = (client_dt_norm is not None and client_dt_norm == bedrock_dt_norm)
                        # –°—Ä–æ–∫ –∞–∫—Ç—É–∞–ª—å–Ω–æ—Å—Ç–∏
                        doc_type_for_validity = bedrock_dt_norm or client_dt_norm
                        days = VALIDITY_DAYS.get(doc_type_for_validity) if doc_type_for_validity else None
                        issue_date = parse_date_safe(parsed.get("–î–∞—Ç–∞ –≤—ã–¥–∞—á–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞"))
                        valid_until = None
                        is_valid_now = None
                        if days is not None and issue_date is not None:
                            valid_until = (issue_date.toordinal() + days)
                            valid_until_date = datetime.fromordinal(valid_until).date()
                            is_valid_now = datetime.utcnow().date() <= valid_until_date
                            checks["valid_until"] = valid_until_date.isoformat()
                            checks["is_valid_now"] = is_valid_now
                        else:
                            checks["valid_until"] = None
                            checks["is_valid_now"] = None
                        # –ü–µ—á–∞—Ç—å/QR
                        si = parsed.get("_stamps") if isinstance(parsed.get("_stamps"), dict) else {}
                        checks["stamp_or_qr_present"] = True if (si.get("stamp_present") is True or si.get("qr_present") is True) else (False if (si.get("stamp_present") is False and si.get("qr_present") is False) else None)
                        # PDF —Å—Ç—Ä–∞–Ω–∏—Ü—ã
                        if st.session_state.get("last_is_pdf"):
                            pc = st.session_state.get("pdf_page_count")
                            checks["pdf_has_one_page"] = (pc == 1) if isinstance(pc, int) else None
                            checks["pdf_page_count"] = pc if isinstance(pc, int) else None
                        else:
                            checks["pdf_has_one_page"] = None
                            checks["pdf_page_count"] = None
                        parsed["_checks"] = checks

                        # --- –ò—Ç–æ–≥–æ–≤—ã–π –≤–µ—Ä–¥–∏–∫—Ç –ø–æ –ø—Ä–æ–≤–µ—Ä–∫–∞–º ---
                        bools = [
                            checks.get("fio_match"),
                            checks.get("doc_type_match"),
                            checks.get("is_valid_now"),
                            checks.get("stamp_or_qr_present"),
                            checks.get("pdf_has_one_page"),
                        ]
                        evaluated_bools = [b for b in bools if isinstance(b, bool)]
                        if any(b is False for b in evaluated_bools):
                            checks["verdict"] = "fail"
                        elif evaluated_bools and all(b is True for b in evaluated_bools):
                            checks["verdict"] = "pass"
                        else:
                            checks["verdict"] = "unknown"

                        # --- –§–æ—Ä–º–∏—Ä—É–µ–º —Å–ø–∏—Å–æ–∫ –æ—à–∏–±–æ–∫ –ø–æ —Å—Ç–∞–Ω–¥–∞—Ä—Ç—É –ú–ò–ë ---
                        errors = []
                        def _push_err(field_key: str):
                            err = MIB_ERRORS.get(field_key)
                            if err:
                                errors.append({"field": field_key, "code": err.get("code"), "message": err.get("message")})

                        # –§–ò–û –Ω–µ —Å–æ–≤–ø–∞–¥–∞–µ—Ç
                        if checks.get("fio_match") is False:
                            _push_err("–§–ò–û –∑–∞—è–≤–∏—Ç–µ–ª—è –∏ –§–ò–û –≤ –¥–æ–∫—É–º–µ–Ω—Ç–µ –¥–æ–ª–∂–Ω—ã —Å–æ–≤–ø–∞–¥–∞—Ç—å")
                        # –¢–∏–ø –¥–æ–∫—É–º–µ–Ω—Ç–∞ –Ω–µ —Å–æ–≤–ø–∞–¥–∞–µ—Ç (–∏—Å–ø–æ–ª—å–∑—É–µ–º –∫–æ–¥/—Å–æ–æ–±—â–µ–Ω–∏–µ –¥–ª—è –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞)
                        if checks.get("doc_type_match") is False:
                            _push_err("–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞")
                        # –°—Ä–æ–∫ –∞–∫—Ç—É–∞–ª—å–Ω–æ—Å—Ç–∏ –∏—Å—Ç—ë–∫
                        if checks.get("is_valid_now") is False:
                            _push_err("–ê–∫—Ç—É–∞–ª—å–Ω–∞—è –¥–∞—Ç–∞")
                        # –ù–µ—Ç –ø–µ—á–∞—Ç–∏ –∏ –Ω–µ—Ç QR
                        if checks.get("stamp_or_qr_present") is False:
                            _push_err("–ù–∞–ª–∏—á–∏–µ QR –∏–ª–∏ –ø–µ—á–∞—Ç–∏")
                        # PDF —Å–æ–¥–µ—Ä–∂–∏—Ç –Ω–µ –æ–¥–Ω—É —Å—Ç—Ä–∞–Ω–∏—Ü—É
                        if checks.get("pdf_has_one_page") is False:
                            _push_err("–ü—Ä–∏–∫—Ä–µ–ø–ª–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å –æ–¥–∏–Ω –¥–æ–∫—É–º–µ–Ω—Ç")

                        parsed["_errors"] = errors
                    except Exception:
                        # –ù–µ –ª–æ–º–∞–µ–º –ø—Ä–æ—Ü–µ—Å—Å, –µ—Å–ª–∏ —á—Ç–æ-—Ç–æ –ø–æ—à–ª–æ –Ω–µ —Ç–∞–∫
                        parsed["_checks"] = {"error": "check_failed"}
                        parsed["_errors"] = [{"code": "unknown", "message": "check_failed"}]

                    status.update(label="–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ JSON –≤ S3...", state="running")
                    folder = key.rsplit("/", 1)[0] + "/" if "/" in key else ""
                    json_key = f"{folder}extraction-{datetime.utcnow().strftime('%Y%m%d-%H%M%S')}.json"
                    payload = json.dumps(parsed, ensure_ascii=False, indent=2).encode("utf-8")
                    bio = io.BytesIO(payload)
                    s3.upload_fileobj(
                        Fileobj=bio,
                        Bucket=BUCKET_NAME,
                        Key=json_key,
                        ExtraArgs={"ContentType": "application/json; charset=utf-8"},
                    )
                    status.update(label="–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞", state="complete")
                progress.progress(100)

                # ===================== –†–ï–ó–£–õ–¨–¢–ê–¢ (—É–ª—É—á—à–µ–Ω–Ω—ã–π UI) =====================
                st.markdown("### –†–µ–∑—É–ª—å—Ç–∞—Ç")

                # –ë—ã—Å—Ç—Ä—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –∏ —Å—Ç–∞—Ç—É—Å—ã
                signatures_info = parsed.get("_signatures") or {}
                stamps_info = parsed.get("_stamps") or {}
                signatures = signatures_info.get("signatures") or [] if isinstance(signatures_info, dict) else []
                # –î–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º —ç—Ç–æ –∑–Ω–∞—á–µ–Ω–∏–µ –Ω–∞–ø—Ä—è–º—É—é
                stamp_present = stamps_info.get("stamp_present") if isinstance(stamps_info, dict) else None

                # –°–æ–æ–±—â–µ–Ω–∏–µ –æ–± –æ—à–∏–±–∫–∞—Ö –∏–∑–≤–ª–µ—á–µ–Ω–∏—è
                llm_error = parsed.get("–û—à–∏–±–∫–∞")
                sig_err = signatures_info.get("error") if isinstance(signatures_info, dict) else None
                stamp_err = stamps_info.get("error") if isinstance(stamps_info, dict) else None
                if llm_error:
                    st.error(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ LLM: {llm_error}")
                if sig_err:
                    st.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–∏ –ø–æ–¥–ø–∏—Å–µ–π: {sig_err}")
                if stamp_err:
                    st.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–∏ –ø–µ—á–∞—Ç–µ–π: {stamp_err}")

                # –¢–∞–±—ã: –ü—Ä–æ–≤–µ—Ä–∫–∞ | –î–µ—Ç–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ | –ü—Ä–µ–≤—å—é | –°—Ç—Ä—É–∫—Ç—É—Ä–∞ | JSON
                tab_verify, tab_detail, tab_preview, tab_structure, tab_json = st.tabs(["–°–≤–æ–¥–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞", "–î–µ—Ç–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞", "–ü—Ä–µ–≤—å—é –¥–æ–∫—É–º–µ–Ω—Ç–∞", "–°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–æ–ª—è", "–°—ã—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ (JSON)"])

                # --- –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–æ–ª—è ---
                with tab_structure:
                    # –û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞—Ç—å —Å–ª—É–∂–µ–±–Ω—ã–µ –∫–ª—é—á–∏
                    user_fields = {k: v for k, v in parsed.items() if not str(k).startswith("_") and k != "–û—à–∏–±–∫–∞"}
                    if not user_fields:
                        st.info("–ù–µ—Ç –∏–∑–≤–ª–µ—á—ë–Ω–Ω—ã—Ö –ø–æ–ª–µ–π –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è.")
                    else:
                        # –¢–∞–±–ª–∏—á–Ω–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ: –æ–¥–Ω–∞ —Å—Ç—Ä–æ–∫–∞ = –æ–¥–Ω–∞ –ø–∞—Ä–∞ (–∫–ª—é—á, –∑–Ω–∞—á–µ–Ω–∏–µ)
                        items = list(user_fields.items())
                        rows = [{"–ü–æ–ª–µ": k, "–ó–Ω–∞—á–µ–Ω–∏–µ": (v if v not in (None, "") else "‚Äî")} for k, v in items]

                        # –î–æ–±–∞–≤–ª—è–µ–º –∞–≥—Ä–µ–≥–∞—Ç –ø–æ –ø–æ–¥–ø–∏—Å—è–º –∫–∞–∫ –æ—Ç–¥–µ–ª—å–Ω—É—é –∑–∞–ø–∏—Å—å
                        try:
                            if signatures:
                                confidences = [s.get("confidence") for s in signatures if isinstance(s, dict) and s.get("confidence") is not None]
                                if confidences:
                                    max_conf = max(confidences)
                                    # Textract –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç [0..100]
                                    cr_text = f"–æ–±–Ω–∞—Ä—É–∂–µ–Ω (CR {round(max_conf)}%)"
                                else:
                                    cr_text = "–æ–±–Ω–∞—Ä—É–∂–µ–Ω"
                            else:
                                cr_text = "–Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω"
                        except Exception:
                            cr_text = "–Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω"
                        # –ù–µ –¥–æ–±–∞–≤–ª—è–µ–º —Å—Ä–∞–∑—É; –ø–µ—Ä–µ–Ω–µ—Å—ë–º –≤ –∫–æ–Ω–µ—Ü —Ç–∞–±–ª–∏—Ü—ã

                        # –î–æ–±–∞–≤–ª—è–µ–º –∞–≥—Ä–µ–≥–∞—Ç –ø–æ –ø–µ—á–∞—Ç–∏ –∏–∑ LLM
                        try:
                            if isinstance(stamps_info, dict) and stamps_info.get("stamp_present") is True:
                                conf = stamps_info.get("stamp_confidence")
                                if isinstance(conf, (int, float)):
                                    stamp_text = f"–æ–±–Ω–∞—Ä—É–∂–µ–Ω–∞ (CR {round(conf)}%)"
                                else:
                                    stamp_text = "–æ–±–Ω–∞—Ä—É–∂–µ–Ω–∞"
                            elif isinstance(stamps_info, dict) and stamps_info.get("stamp_present") is False:
                                stamp_text = "–Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∞"
                            else:
                                stamp_text = "–Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–æ"
                        except Exception:
                            stamp_text = "–Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–æ"
                        
                        # –î–æ–±–∞–≤–ª—è–µ–º –∞–≥—Ä–µ–≥–∞—Ç –ø–æ QR –∏–∑ LLM
                        try:
                            if isinstance(stamps_info, dict) and stamps_info.get("qr_present") is True:
                                qconf = stamps_info.get("qr_confidence")
                                if isinstance(qconf, (int, float)):
                                    qr_text = f"–æ–±–Ω–∞—Ä—É–∂–µ–Ω (CR {round(qconf)}%)"
                                else:
                                    qr_text = "–æ–±–Ω–∞—Ä—É–∂–µ–Ω"
                            elif isinstance(stamps_info, dict) and stamps_info.get("qr_present") is False:
                                qr_text = "–Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω"
                            else:
                                qr_text = "–Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–æ"
                        except Exception:
                            qr_text = "–Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–æ"

                        # –ü–µ—Ä–µ–º–µ—â–∞–µ–º "–ü–æ–¥–ø–∏—Å—å", "–ü–µ—á–∞—Ç—å" –∏ "QR-–∫–æ–¥" –≤ –∫–æ–Ω–µ—Ü —Å–ø–∏—Å–∫–∞
                        rows.extend([
                            {"–ü–æ–ª–µ": "–ü–æ–¥–ø–∏—Å—å", "–ó–Ω–∞—á–µ–Ω–∏–µ": cr_text},
                            {"–ü–æ–ª–µ": "–ü–µ—á–∞—Ç—å", "–ó–Ω–∞—á–µ–Ω–∏–µ": stamp_text},
                            {"–ü–æ–ª–µ": "QR-–∫–æ–¥", "–ó–Ω–∞—á–µ–Ω–∏–µ": qr_text},
                        ])

                        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∏–Ω–¥–µ–∫—Å DataFrame, –Ω–∞—á–∏–Ω–∞—è —Å 1 (–±–µ–∑ –æ—Ç–¥–µ–ª—å–Ω–æ–π –∫–æ–ª–æ–Ω–∫–∏ "‚Ññ")
                        df = pd.DataFrame(rows)
                        df.index = range(1, len(df) + 1)
                        st.table(df)

                # --- –ü—Ä–µ–≤—å—é –¥–æ–∫—É–º–µ–Ω—Ç–∞ ---
                with tab_preview:
                    st.markdown("#### –ü—Ä–µ–≤—å—é –¥–æ–∫—É–º–µ–Ω—Ç–∞")
                    previews = st.session_state.get("pdf_previews") if "pdf_previews" in st.session_state else None
                    if previews and not previews.get("error") and previews.get("local_paths"):
                        for p in previews["local_paths"][:3]:
                            st.image(p, caption=os.path.basename(p), use_container_width=True)
                        if previews.get("s3_keys"):
                            st.caption("S3 –ø—Ä–µ–≤—å—é:")
                            for k in previews["s3_keys"]:
                                st.code(f"s3://{BUCKET_NAME}/{k}")
                    elif previews and previews.get("error"):
                        st.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–µ–≤—å—é –¥–æ–∫—É–º–µ–Ω—Ç–∞: {previews['error']}")
                    else:
                        st.caption("–ü—Ä–µ–≤—å—é –¥–æ—Å—Ç—É–ø–Ω–æ —Ç–æ–ª—å–∫–æ –¥–ª—è PDF-—Ñ–∞–π–ª–æ–≤ –ø–æ—Å–ª–µ –∑–∞–≥—Ä—É–∑–∫–∏.")

                # --- –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–π (–ø–µ—Ä–≤—ã–π —Ç–∞–±) ---
                with tab_verify:
                    errors_list = parsed.get("_errors") or []
                    checks = parsed.get("_checks") or {}
                    # –ü–æ–¥—Å—á—ë—Ç –ø—Ä–æ–≤–µ—Ä–æ–∫, –ø–æ –∫–æ—Ç–æ—Ä—ã–º –µ—Å—Ç—å —Ä–µ—à–µ–Ω–∏–µ (True/False)
                    evaluated = [v for v in [
                        checks.get("fio_match"),
                        checks.get("doc_type_match"),
                        checks.get("is_valid_now"),
                        checks.get("stamp_or_qr_present"),
                        checks.get("pdf_has_one_page"),
                    ] if isinstance(v, bool)]
                    total_evaluated = len(evaluated)
                    fails = sum(1 for v in evaluated if v is False)
                    passes = sum(1 for v in evaluated if v is True)

                    csum1, csum2, csum3 = st.columns(3)
                    with csum1:
                        st.metric(label="–ü—Ä–æ–≤–µ—Ä–∫–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω—ã", value=total_evaluated)
                    with csum2:
                        st.metric(label="–£—Å–ø–µ—à–Ω–æ", value=passes)
                    with csum3:
                        st.metric(label="–û—à–∏–±–∫–∏", value=len(errors_list))

                    # –ò—Ç–æ–≥–æ–≤—ã–π –≤–µ—Ä–¥–∏–∫—Ç
                    verdict = checks.get("verdict")
                    if verdict == "pass":
                        st.success("–ò—Ç–æ–≥: –¥–æ–∫—É–º–µ–Ω—Ç –ø—Ä–æ—à—ë–ª –ø—Ä–æ–≤–µ—Ä–∫—É.")
                    elif verdict == "fail":
                        st.error("–ò—Ç–æ–≥: –¥–æ–∫—É–º–µ–Ω—Ç –Ω–µ –ø—Ä–æ—à—ë–ª –ø—Ä–æ–≤–µ—Ä–∫—É.")
                    else:
                        st.info("–ò—Ç–æ–≥: –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–∫–æ–Ω—á–∞—Ç–µ–ª—å–Ω–æ–≥–æ –≤–µ—Ä–¥–∏–∫—Ç–∞.")

                # --- –î–µ—Ç–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ (–≤—Å—è –ø–æ–¥—Ä–æ–±–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è) ---
                with tab_detail:
                    render_detailed_checks(parsed)

                # --- –°—ã—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ ---
                with tab_json:
                    st.json(parsed)
                    st.download_button(
                        label="–°–∫–∞—á–∞—Ç—å JSON",
                        data=json.dumps(parsed, ensure_ascii=False, indent=2).encode("utf-8"),
                        file_name="extraction.json",
                        mime="application/json",
                        use_container_width=True,
                    )

            except ClientError as e:
                err = e.response.get("Error", {})
                st.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {err.get('Code', 'Unknown')} - {err.get('Message', str(e))}")
            except Exception as e:
                st.error(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–µ —É–¥–∞–ª–∞—Å—å: {e}")

        except NoCredentialsError:
            st.error("AWS-—É—á—ë—Ç–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã. –ù–∞—Å—Ç—Ä–æ–π—Ç–µ –∏—Ö —á–µ—Ä–µ–∑ ~/.aws/credentials –∏–ª–∏ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è.")
        except ClientError as e:
            err = e.response.get("Error", {})
            st.error(f"AWS ClientError: {err.get('Code', 'Unknown')} - {err.get('Message', str(e))}")
        except (BotoCoreError, Exception) as e:
            st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ: {e}")
